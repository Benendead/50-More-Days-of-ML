Day 1: August 25th, 2018 (0 extra hours studied)
Today's Progress: I began the reformatting of this studying system and also began the Conducting project. The progress I made on that today was first reading one project on hand rcognition using OpenCV and then installing Homebrew and OpenCV. I then worked on configuring my laptop and XCode in preparation for some prototyping or testing of concepts in iOS OpenCV.
Thoughts: My laptop is really slow and I should get another 8GB of RAM when that's possible. Also, I don't want to get too dragged down in technical installations if OpenCV's quite difficult; I should transition to a school computer if this gives me much more trouble in getting started with XCode and OpenCV.

Day 2: August 26th, 2018 (0 extra hours studied)
Today's Progress: Installed PyCharm Community as an IDE for testing OpenCV, also cloned an OpenCV repository for XCode although it seems like that won't be needed. Also found two tutorials worth pursuing once everything's installed.
Thoughts: Installing is boring and slow, but by reading ahead in articles and checking other tangents, I managed to feel productive. Hope tomorrow I can run some code on my own machine.

Day 3: August 27th, 2018 (0 extra hours studied)
Today's Progress: Absolutely nothing. Spent an hour trying to install OpenCV into PyCharm, open Jupyter Notebook as an alternative, and overall just had a terrible experience trying to get this to work. If Jupyter doesn't pan out tomorrow, I'm goign to stop trying; it's far too infuriating.
Thoughts: Pissed off because installing something into PyCharm should NOT be this hard. My laptop's stupidly slow as well, so I have no idea what to do other than abandon this tangent if nothing works out.

Day 4: August 28th, 2018 (0 extra hours studied)
Today's Progress: Finally got OpenCV to work by using it in Jupyter Notebook. Opened an image, showed it in-notebook, masked it, and got video webcam feed working too. Tomorrow I'll work on implementing select pixels by mouse-click maybe to select the colors to detect skin with.
Thoughts: It's hella rewarding to finally have some results. This is why I'm doing this work.

Day 5: August 29th, 2018 (1 extra hour studied)
Today's Progress: Continued working on getting video to display well from OpenCV running in a Jupyter Notebook. Tried multiple approaches, few to none worked. I think using the video window that cannot close is likely the best for taking a mouse input, but I should look into the setdata and other mouse options one more time.
Thoughts: Made little progress, but I was building using others' code, so I somehow still felt like I was learning.
Another hour: Continued trying out things with the video player, started looking into ScikitLearn, and also managed to mask my live video as a proof-of-concept. Mouse input seems to be infeasible with the resources I can find now.

Day 6: August 31st, 2018 (0 extra hours studied)
Missed yesterday.
Today's Progress: Completed a video series on decision trees and then began to implement my own coding of decision trees/random forests to classify the Titanic dataset on Kaggle.
Thoughts: Felt like I understood this iteration of decision tree content, might want to fill in the hard parts as I code it out but otherwise don't want to redundantly repeat much more.

Days 7-9: September 3rd, 2018 (-1 extra hours studied)
Missed two days and then made up with two hours today.
Today's Progress: Spent two hours studying pandas dataframe methods in an effort to enable my future development of a random forest to solve Kaggle's Titanic problem.
Thoughts: Shouldn't fall behind again, duh. Still making directional progress though.

Day 10: September 4th, 2018 (-1 extra hours studied, for shame)
Today's Progress: Finished one introduction to pandas, then spent the remainder of the hour studying cross validation techniques, as the Kaggle decision tree article I was trying to follow referenced them.
Thoughts: The rabbit hole grows ever deeper, but at least I'm still learning new things. Might want Shiffman or deep-fried memes soon.

Days 11 and 12: September 6th, 2018 (-1 extra hours studied, for shame)
Today's Progress: Spent two hours working through more of the Random Forests paper for Deep Dive 1. I felt like I was getting most of the initial math, and definitely on my way to understanding the algorithm itself. Now I'm about halfway through the essay, hope I can finish it soon.
Thoughts: Feeling good about my understanding and glad I fit two hours into one day. Maybe it helps to catch up a bit, or at least avoid falling behind further.

Days 13 and 14: September 8th, 2018 (-2 extra hours studied, for extra shame)
Today's Progress: Continuing through the random forests paper while struggling to stay awake, practically. The latter half is getting dense and I knew to skip certain math parts, but tomorrow I'll need to buckle down and read over the bits I skipped, at least broadly.
Thoughts: This paper's definitely getting old and I'd prefer to do something more interesting.

Days 15 and 16: September 10th, 2018 (-2 extra hours studied, for extra shame)
Today's Progress: Spent one hour on the random forest paper and one hour on deep fried meme research. Currently defining the goals for my project and its metrics for success.
Thoughts: Memes are fun and there's a surprising amount of work I could put into a Meme Deep Frier if I went all-in.

Day 17: September 11th, 2018 (-1 extra hours studied, for a bit less shame)
Today's Progress: Spent two hours today beginning to implement a random forest algorithm on the Titanic data set from Kaggle. So far can split a dataframe on a given feature and calculate the Gini score for that split.
Thoughts: Actually coding my own stuff is pretty rewarding. Hyped to continue my progress.

Day 18: September 12th, 2018 (-1 extra hours studied, for minute shame)
Today's Progress: Developed methods to categorize the data for the Titanic problem more smoothly. Also tested the Gini scores of each new category and also cleaned up the general previews given in the Jupyter Notebook so far.
Thoughts: I reached a roadblock on actually coding a decision tree without anything but found a Jason Brownlee tutorial on it. Head through that and we'll be good to go.

Days 19 and 20: September 14th, 2018 (-2 extra hours studied, I'll fix this soon)
Today's Progress: Had the first meeting of the robotics club and I think the problem we're working on will have applications in reinforcement learning once it works. Spent the hour studying transformation matrices and began trying to animate that process in Jupyter Notebooks, which turns out to be difficult.
Thoughts: Plotting and animation is hard.

Day 21: September 15th, 2018 (-1 extra hours studied, fixing this)
Today's Progress: of the two hours today, spent one and a half learning how to animate in Jupyter Notebook from a tutorial. Then went entirely through his code to annotate methods and develop a better understanding of what was actually happening. For the rest of my time, I've been working on first hand-writing my understanding of forward transformation matrices and then began coding a ReferenceFrame2D class to try to illustrate the intuitions I'm struggling with. Almost through with the class and I now just need to plot each frame's axes as lines, animate them somehow, and boom it's done. Long road ahead.
Thoughts: Shiffman always calls. Someday soon.

Days 22 and 23: September 17th, 2018 (-2 extra hours studied, now not fixing this)
Today's Progress: Continued work on the rotational matrices thing. Coding it without my notes for intuition is absolutely an error. Tomorrow I should shift the entire thing into numpy arrays/matrices so I can begin the math part. Still, logic building is good coding practice.
Thoughts: Yet again behind on hours, but I think that I'm pushing myself in terms of learning coding here nonetheless. Hope that this interesting challenge might motivate me to catch up.

Day 24: September 18th, 2018 (-2 extra hours studied)
Today's Progess: I continued working on the reference frame project, but quickly realized that I had little idea what to do. Spent the other half of the hour learning how/why the translational matrix works. Then derived the translation + rotation "combo matrix" using my own math by hand.
Thoughts: Now that I actually understand the math behind my goal, I hope that I can implement this fairly quickly later tonight/tomorrow. Seems simple enough now.

Day 25: September 19th, 2018 (-2 extra hours studied)
Today's Progess: Revamped the reference frame class by dismantlign it briefly. Replaced part of it with a developing translation matrix class, which just makes more sense to implement externally from the frames.
Thoughts: Writing this the day after but it's separate work and I did do it, just want to wrap that day's description up before working today.

Day 26: September 20th, 2018 (-1.5 extra hours studied)
Today's Progess: Spent *an hour and a half* working to fix the matrix multiplication so it translates things in a way that makes sense. No success.
Thoughts: To avoid permanently quitting this overall system, I'll work on broader ML goals tomorrow. Enough coding for a bit, I feel.

Day 27: September 21st, 2018 (-1.5 extra hours studied)
Today's Progess: Studied inner workings of CNNs for twenty minutes, then spent the rest of my hour installing Keras, Theano, TensorFlow, and other dependencies. Am currently having trouble importing Keras into a project because the TensorFlow compile version is having issues with the runtime version.
Thoughts: Installation issues suck. Still, I finally installed something I've heard about for years.

Day 28: September 22nd, 2018 (-1.5 extra hours studied)
Today's Progress: I ended up fixing the TensorFlow issue by downgrading my version. Spent the rest of my time between an introductory Keras guide and an explanation of various GD optimization methods. Before using any algorithm, I plan to understand it first.
Thoughts: I'm rounding out my background and filling in a lot of the gaps in my knowledge, which feels really satisfying yet still like comfortably familiar concepts.

Day 30: September 24th, 2018 (-1.5 extra hours studied)
Today's Progress: I studied for two hours today. For the first hour, I continued learning about various optimization methods for gradient descent. This continued up to RMSprop, and I left the rest of the article for a more ML-literate me. The second hour, I devoted my time to continuing through one tutorial on the MNIST dataset. I created my own method for randomly picked and plotting 4 training examples. Also preprocessed the data.
Thoughts: I had some troubles as I tried to import the MNIST data set, but between a few StackOverflow questions and a commandline saving grace, I managed to download the data set directly in the code itself.

Day 31: September 25th, 2018 (-1.5 extra hours studied)
Today's Progress: Continuing with the tutorial I've been following, I finished coding my first CNN (using Keras). Its loss was 6.1700069572448735 and the accuracy 0.098. That seems bad. But hey, it ran even on my crappy laptop and I therefore think there's hope yet.
Thoughts: I should figure out how to use callbacks in Keras, gain the ability to pause training, and then start making a system so that I can train algorithms using (much faster) school computers.

Day 32: September 26th, 2018 (-1.25 extra hours studied)
Today's Progress: Spent some time learning about the Adam optimizer. Rest of the time devoted to trying to improve the Jupyter/Keras/Tensorflow/Python 3.6/virtualenvironment setup, or lack thereof.
Thoughts: Installing things is definitely difficult. I should likely begin with a fresh virtual environment and fully go through the setup, operation, and maintenance of a virtual environment before trying to use one again.

Days 33, 34: September 28th, 2018 (-1.25 extra hours studied)
Today's Progress: Failed at trying to transition my notebook entirely into Kaggle's site, so I instead imported Kaggle's datasets in my notebook on my own machine. Managed to format that, train, and test using that data before making my first submission on Kaggle. All that's left for this project is to add the ability to save/load the entire trained CNN and to publish the fixed notebook to my Github. Hype.
Thoughts: As I said, hype.

Day 35: September 29th, 2018 (-0.5 extra hours studied)
Today's Progress: I implemented a means to save and load models from Keras before training a single model 15 total epochs. Submitted this new PB on accuracy, saved it, and then moved on to the Two Sigma project. I've read through this challenge's description as well as compiled some sources to read through about stock market predictions using news.
Thoughts: Want to make sure that I'm moving forward on this project while creating an intelligent foundation in the hypothetically new area. We'll see.

Days 36, 37: October 1st, 2018 (0 extra hours studied)
Today's Progress: I worked on Raspberry Pi servo control, wiring up GPIO inputs intelligently, and beginning a keyboard circuit in order to learn about GPIO's Button class.
Thoughts: Intermediate Raspberry Pi knowledge doesn't immediately translate to ML applications, but I think it's a necessary step in working with this new system.
